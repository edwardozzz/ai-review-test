llm:
  provider: OLLAMA

  meta:
    model: mistral
    temperature: 0.2
    max_tokens: 2048

  http_client:
    api_url: http://host.docker.internal:11434
    timeout: 600
    headers: {}
    verify_ssl: false

  llm_kwargs: {}

vcs:
  provider: GITHUB

  pipeline:
    provider: GITHUB_ACTIONS
    workspace: /app
    owner: edwardozzz
    repo: ai-review-test
    pull_number: "1"
    sha: d2b5d1e4f9332c1224f2f7d1635a8461614a5f68
    ref: refs/pull/3/head

  http_client:
    api_url: https://api.github.com
    api_token: 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
    timeout: 60
    headers: {}
    verify_ssl: true

  owner: edwardozzz
  repository: ai-review-test
  pull_number: "1"

review:
  fail_on_severity: NONE
  max_files: 100
  max_diff_size: 500000
  exclude_paths: []
  include_extensions: []

runtime:
  dry_run: true
  clear_inline_comments: false
  parallelism: 1
